# NLP 220
## Introduction to Data Science and ML
## Luca de Alfaro, University of California, Santa Cruz

F = Fundamental

1. Introduction
    * List of topics
    * Overview of the course structure
    * Probability
    * Probability space, measure spaces, events, random variables.

1. Foundations of probability (F)
    * Events and compound events
    * Independent and uncorrelated events
    * Random variables
    * Independence

1. Expectation and variance, conditional probability. (F)
    * Expectation and variance
    * Conditional probability
    * Bayes' theorem
        * Example (rust)
    * Covariance and correlation
    * Independence and dependence
    * Probability density functions (PDFs)
    * Cumulative distribution functions (CDFs)

1. Distributions (F)
    * Uniform distribution
    * Normal distribution
    * Binomial distribution
    * Poisson distribution
    * Exponential distribution
    * Bernoulli distribution
    * Bernoulli and binomial distributions in crowdsourcing
    * Some theorems:
        * Distribution of sums
        * Central Limit Theorem
        * Law of Large Numbers

1. Hypothesis testing (F)
    * Null hypothesis
    * Alternative hypothesis
    * p-values
    * Type I and Type II errors
    * Confidence intervals
    * Statistical significance
    * Welch's t-test
    * Chi-squared test
    * K-fold cross-validation (?)

1. Information theory (F)
    * Information
    * Entropy
    * Joint entropy
    * Kulback-Leibler divergence
    * Cross-entropy
    * Mutual information
    * Earth-mover's distance

1. Data (sec)
    * Understanding data types
    * Pandas dataframes and their operations
    * Data types (numerical, categorical)
    * One-hot encoding
    * Discretization (example of when wrong discretization can impact learning)
    * Binning
    * Data normalization
    * Data cleaning, dealing with outliers and missing data
    * Data visualization

1. NLP data (F)
    * Text data representation
    * Tokenization
    * Regular expressions
    * N-grams
    * Bag of words model

1. Text representation
    * One-hot encoding
    * Bag of words
    * TF-IDF (Term Frequency-Inverse Document Frequency)
    * Word Embeddings
        * Word2Vec
        * GloVe
        * FastText

1. Dimensionality Reduction
    * Principal Component Analysis (PCA)
    * Singular Value Decomposition (SVD)
    * t-Distributed Stochastic Neighbor Embedding (t-SNE)
    * Topic Modeling
    * Latent Dirichlet Allocation (LDA)
    * Non-negative Matrix Factorization (NMF)

1. Unsupervised methods (F)
    * Clustering
        * K-means clustering
        * Hierarchical clustering
        * DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
    * Classification
        * K-nearest neighbors (KNN)

1. Sampling methods (?)
    * Random sampling
    * Stratified sampling
    * Systematic sampling
    * Cluster sampling

1. Supervised methods 1 (F)
    * Linear Regression
    * Logistic Regression
    * Softmax and multi-class classification

1. Supervised methods 2 (F)
    * Naive Bayes Classifier
        * Gaussian Naive Bayes
        * Multinomial Naive Bayes
        * Bernoulli Naive Bayes
    * Ensemble Methods
        * Bagging
        * Boosting

1. Tree-based methods (F)
    * Decision Trees
        * Entropy
        * Gini impurity 
        * Overfitting
    * Random Forests
    * Gradient Boosting Machines (GBM)

1. Neural Networks 1, 2 (F)
    * Feedforward Neural Networks
    * Activation Functions
        * Sigmoid
        * ReLU
        * Tanh
        * Softmax
    * Loss functions
        * Mean Squared Error
        * Cross-Entropy Loss
    * Gradient Descent
        * Stochastic Gradient Descent
        * Mini-batch Gradient Descent

1. Neural Networks 3 (no)
    * Optimizers
        * Momentum
        * Adam Optimizer
        * Learning Rate Scheduling
    * Regularization
        * L1 and L2 Regularization
        * Dropout    
        * Batch Normalization
        * Layer Normalization

1. Inside PyTorch (F)
    * Representing expressions
    * Symbolic differentiation
    * Backpropagation
    * Training

1. Performance monitoring (F)
    * Measures of performance for ML
    * Data drift
    * Divergence, DivExplorer
    * Fairness in Machine Learning

1. Explainable AI 
    * Feature Importance
    * SHAP Values
    * LIME (Local Interpretable Model-agnostic Explanations)
    * Model Interpretability

1. Data Mining (?)
    * Association Rule Learning
        * Apriori Algorithm
        * FP-Growth Algorithm




